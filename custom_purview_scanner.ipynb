{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Getting Started\n",
    "\n",
    "ðŸ’¡<b> Before running this notebook</b>, ensure you have configured SharePoint, Azure AI Foundry, set up an application for handling API authentication, granted appropriate roles in Microsoft Purview, and set the appropriate configuration parameters. [Steps listed here.](README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The JSON module could be potentially removed\n",
    "import json\n",
    "from azure.identity import ClientSecretCredential\n",
    "from pyapacheatlas.core import PurviewClient\n",
    "from purviewautomation import PurviewCollections, ServicePrincipalAuthentication\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pyapacheatlas.core.typedef import ClassificationTypeDef, EntityTypeDef\n",
    "# Purview custom libraries\n",
    "from custom_libs.purview_utils import (\n",
    "    filesystemFileSampleList,\n",
    "    listFilesystemFiles,\n",
    "    getAADToken,\n",
    "    moveCollection,\n",
    "    estimateTokens,\n",
    "    unstructuredDataClassification,\n",
    "    rollupClassifications,\n",
    "    loadPurviewAssets,\n",
    "    applyPurviewClassifications\n",
    ")\n",
    "# SharePoint custom libraries\n",
    "from custom_libs.sharepoint_utils import (\n",
    "    SharePointUtils,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initialize Environment\n",
    "\n",
    "Before running this notebook, you must configure certain environment variables. We will now use environment variables to store our configuration. This is a more secure practice as it prevents sensitive data from being accidentally committed and pushed to version control systems.\n",
    "\n",
    "Create a `.env` file in your project root (use the provided `.env.sample` as a template). [Detailed steps here](README.md)\n",
    "\n",
    "> ðŸ“Œ **Note**\n",
    "> Remember not to commit the .env file to your version control system. Add it to your .gitignore file to prevent it from being tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SharePointDataExtractor client\n",
    "# The client handles the complexities of interacting with SharePoint's REST API, providing an easy-to-use interface for data extraction.\n",
    "sharepointClient = SharePointUtils()\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "sharepointClient.loadEnvFile()\n",
    "\n",
    "# Retrieve environment variables\n",
    "azureOpenAIApiKey=os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "azureOpenAIDeploymentName=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "azureOpenAILLMModel=os.getenv(\"AZURE_OPENAI_LLM_MODEL\")\n",
    "azureOpenAIApiEndpoint= os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azureOpenAIApiVersion= os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "purviewAccountName = os.getenv(\"PURVIEW_ACCOUNT_NAME\")\n",
    "purviewEndpointUrl=os.getenv(\"PURVIEW_ENDPOINT_URL\")\n",
    "purviewTokenUrl=os.getenv(\"PURVIEW_TOKEN_URL\")\n",
    "tenantId=os.getenv(\"AZURE_TENANT_ID\")\n",
    "clientId=os.getenv(\"AZURE_CLIENT_ID\")\n",
    "clientSecret=os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "siteDomain = os.getenv(\"SITE_DOMAIN\")\n",
    "siteName = os.getenv(\"SITE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to update the values for the cell below to match the characteristics of your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable or disable display of variables\n",
    "displayVariables = True\n",
    "\n",
    "# Global variable definitions\n",
    "fileExtensions = [\"docx\",\"pdf\",\"pptx\"]\n",
    "sharepointPath=\"/Insurance/Claims\"\n",
    "filesystemPath = r\"SampleFiles\"\n",
    "\n",
    "# Number of characters to be analyzed by Large Language Model (LLM) from each file\n",
    "textLength=800\n",
    "\n",
    "# Sample size for filesystem and SharePoint files\n",
    "sampleSize=0\n",
    "\n",
    "# Entity types for classification\n",
    "entityTypes = ['SharePoint','FileSystem']\n",
    "\n",
    "# List of custom classifications to be created in Purview\n",
    "# This list can be customized based on the specific needs of the organization or project.\n",
    "classifications=[\n",
    "    \"Empty Content\", \n",
    "    \"Insurance Claim\",  \n",
    "    \"Sales Receipt\",  \n",
    "    \"Insurance Policy\",\n",
    "    \"Report\",\n",
    "    \"Invoice\",\n",
    "    \"PII\",\n",
    "    \"Other\"\n",
    "]\n",
    "# Convert classification list to string\n",
    "classificationsStr = ''.join(classification+'\\n' for classification in classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    print(f\"Tenant ID: {tenantId}\")\n",
    "    print(f\"Client ID: {clientId}\") \n",
    "    print(f\"Azure OpenAI API Key: {azureOpenAIApiKey}\")\n",
    "    print(f\"Azure OpenAI Endpoint: {azureOpenAIApiEndpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tenantId or not clientId or not clientSecret or not azureOpenAIApiKey:\n",
    "    raise ValueError(\"Azure credentials are not set in the environment variables.\")\n",
    "\n",
    "# Generate token for REST API calls\n",
    "token = getAADToken(tenantId,clientId, clientSecret,purviewTokenUrl)\n",
    "\n",
    "# Authenticate with Microsoft Graph API\n",
    "response = sharepointClient.msgraph_auth()\n",
    "\n",
    "# Generate authentication credentials for Service Principal and Atlas client authentication for different Purview functions\n",
    "servicePrincipalAuth = ServicePrincipalAuthentication(\n",
    "    tenant_id=tenantId,\n",
    "    client_id=clientId,\n",
    "    client_secret=clientSecret\n",
    ")\n",
    "\n",
    "clientCredential = ClientSecretCredential(\n",
    "    tenant_id=tenantId,\n",
    "    client_id=clientId,\n",
    "    client_secret=clientSecret\n",
    ")\n",
    "\n",
    "# Create clients for Purview administration and Azure AI Foundry\n",
    "purviewClient = PurviewClient(\n",
    "    account_name = purviewAccountName,\n",
    "    authentication = clientCredential\n",
    ")\n",
    "\n",
    "collectionClient = PurviewCollections(\n",
    "    purview_account_name=purviewAccountName,\n",
    "    auth = servicePrincipalAuth\n",
    ")\n",
    "\n",
    "llmClient = ChatCompletionsClient(\n",
    "    endpoint=azureOpenAIApiEndpoint,\n",
    "    credential=AzureKeyCredential(azureOpenAIApiKey),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create Purview asset dependencies\n",
    "\n",
    "Creates entity type definitions and classifications required by the Purview clients to assign classifications to assets discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of custom Entity Types, required by the custom Classifications\n",
    "# The list of Entity Types is taken from the variable named entityTypes\n",
    "for entityName in entityTypes:\n",
    "    edef = EntityTypeDef(\n",
    "        name = entityName,\n",
    "        superTypes= ['DataSet']\n",
    "    )\n",
    "    results = purviewClient.upload_typedefs(\n",
    "        entityDefs=[edef],\n",
    "        force_update=True\n",
    "    )\n",
    "\n",
    "# Creation of custom Classifications\n",
    "# The list of classifications is taken from the variable named classifications\n",
    "for classification in classifications:\n",
    "    # Create custom classifications to be applied to unstructured data assets\n",
    "    cdef = ClassificationTypeDef(\n",
    "        name=classification,\n",
    "        # You need to define the assets type that will be associated with each classification ahead of time.\n",
    "        # entityTypes will restrict the types of assets that can be associated with this classification.\n",
    "        # For example: If the asset has a type of FileSystem and the Classification has entityTypes=['DataSet'],\n",
    "        #              the attempt to classify the asset will fail.\n",
    "        # entityTypes=['SharePoint','FileSystem','DataSet','Process']\n",
    "        entityTypes=entityTypes\n",
    "    )\n",
    "    # Do the upload\n",
    "    results = purviewClient.upload_typedefs(\n",
    "        classificationDefs=[cdef],\n",
    "        force_update=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create custom collections\n",
    "\n",
    "Creates multiple custom collection under the parent Start_Collection (Domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create multiple collections, the parent collection defined by the start_collection parameter\n",
    "# MUST exist.\n",
    "response = collectionClient.create_collections(start_collection=purviewAccountName,\n",
    "                          collection_names=['Unstructured/SharePoint','Unstructured/FileSystem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Capture Sampling Size\n",
    "\n",
    "This will help to determine the number of files that will be analyzed for classification purposes.\n",
    "\n",
    "> ðŸ“Œ **Note:**\n",
    "> Currently is a fixed size, but it could be changed to represent a percentage of the total number of files found during the scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = input(f\"Enter how many documents to analyze: \")\n",
    "if sampleSize.isnumeric():\n",
    "    sampleSize = int(sampleSize)\n",
    "else:\n",
    "    sampleSize = 0\n",
    "print(f\"\\n{sampleSize} documents will be analyzed from the list of documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SharePoint Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Scan SharePoint Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List all the files in SharePoint site that match the defined file extensions. \n",
    "\"\"\"\n",
    "spFileList = sharepointClient.listSharepointFiles(\n",
    "    site_domain=siteDomain,\n",
    "    site_name=siteName,\n",
    "    file_formats = fileExtensions,\n",
    "    folder_path=sharepointPath,\n",
    "    # Files modified N minutes ago\n",
    "    # minutes_ago=60,\n",
    ")\n",
    "print(f\"{len(spFileList)} files found matching the patterns {fileExtensions}: \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables == True:\n",
    "    print(json.dumps(spFileList, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate file subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the spFileList based on the number specified by sampleSize. If no subset is provided, the entire list will be used.\n",
    "if sampleSize == 0 or sampleSize > len(spFileList):\n",
    "        sampleSize = len(spFileList)\n",
    "# Create a subset of the SharePoint file list\n",
    "spFileSubset = sharepointClient.sharepointFileSampleList(spFileList,sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    print(f\"\\nSubset of SharePoint files to be analyzed: {sampleSize} files\\n\")\n",
    "    for file in spFileSubset:\n",
    "        print(f\"{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extract file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract file contents and process all file information included in the subset from a \n",
    "specific Site ID.\n",
    "\"\"\"\n",
    "spFileContent = sharepointClient.getSharepointFileContent(\n",
    "    site_domain=os.environ[\"SITE_DOMAIN\"],\n",
    "    site_name=os.environ[\"SITE_NAME\"],\n",
    "    folder_path=sharepointPath,\n",
    "    file_names=spFileSubset\n",
    "    # Files modified N minutes ago\n",
    "    # minutes_ago=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    print(json.dumps(spFileContent, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Analyze File Contents with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the number of tokens that will be used by LLM model, prior to processing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = estimateTokens(spFileContent,textLength,classificationsStr,azureOpenAILLMModel)\n",
    "print(f\"Estimated Number of Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Classify document contents using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analyze SharePoint folder contents using Large Language Model to determine applicable\n",
    "classifications. \n",
    "\"\"\"\n",
    "spFileContent = unstructuredDataClassification(spFileContent,textLength,llmClient,azureOpenAIDeploymentName,classificationsStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Organize and Rollup Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect document classifications identified for SharePoint folder\n",
    "\"\"\"\n",
    "spClassifications = rollupClassifications(spFileContent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    print(f\"\\nClassifications for SharePoint files: {spClassifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Ingest assets into Purview via Atlas API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load SharePoint Assets in Purview.\n",
    "\"\"\"\n",
    "spGuids = loadPurviewAssets(purviewClient,spFileContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spGuids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Apply classifications to assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apply classification to SharePoint assets\n",
    "\"\"\"\n",
    "result = applyPurviewClassifications(purviewClient,spGuids,spClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Move assets to their final collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Move assets from default (root) collection to collectionName\n",
    "\"\"\"\n",
    "collectionName = 'SharePoint'\n",
    "output = moveCollection(collectionName,purviewEndpointUrl,token,spGuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. File System Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Scan Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "List all the files in Filesystem that match the defined file extensions. \n",
    "\"\"\"\n",
    "fsFileList = listFilesystemFiles(filesystemPath, fileExtensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    for file in fsFileList:\n",
    "        print(f\"{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Generate file subset and extract contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a subset of the fsFileList based on the number specified by sampleSize, extract file \n",
    "contents, and metadata.\n",
    "\"\"\"\n",
    "if sampleSize == 0 or sampleSize > len(spFileList):\n",
    "        sampleSize = len(spFileList)\n",
    "\n",
    "fsFileContent = filesystemFileSampleList(fsFileList,sampleSize,filesystemPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsFileContent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Estimate number of tokens to be used by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = estimateTokens(fsFileContent,textLength,classificationsStr,azureOpenAILLMModel)\n",
    "print(f\"Estimated Number of Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Classify document contents using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analyze Filesystem folder contents using Large Language Model to determine applicable\n",
    "classifications. \n",
    "\"\"\"\n",
    "fsFileContent = unstructuredDataClassification(fsFileContent,textLength,llmClient,azureOpenAIDeploymentName,classificationsStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Organize and Rollup Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Collect document classifications identified for FileSystem folder\n",
    "\"\"\"\n",
    "fsClassifications = rollupClassifications(fsFileContent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    print(f\"\\nClassifications for FileSystem files: {fsClassifications}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Ingest assets into Purview via Atlas API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load FileSystem Assets in Purview.\n",
    "\"\"\"\n",
    "fsGuids = loadPurviewAssets(purviewClient,fsFileContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if displayVariables:\n",
    "    print(f\"\\nFileSystem GUIDs: {fsGuids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Apply classifications to assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apply classification to SharePoint assets\n",
    "\"\"\"\n",
    "result = applyPurviewClassifications(purviewClient,fsGuids,fsClassifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Move assets to their final collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Move collections from default (root) collection to collectionName\n",
    "\"\"\"\n",
    "collectionName = 'FileSystem'\n",
    "output = moveCollection(collectionName,purviewEndpointUrl,token,fsGuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cleanup section\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Delete assets and collections\n",
    "\n",
    "You can delete individual assets using their respective GUIDs or you can leverage the collectionClient to delete collections recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Entities\n",
    "for guid in [*fsGuids, *spGuids]:\n",
    "    response = purviewClient.delete_entity(guid=guid)\n",
    "    print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete sub-collection contents and sub-collections\n",
    "collectionClient.delete_collections_recursively(\"Unstructured\",delete_assets=True)\n",
    "# Delete parent collection\n",
    "collectionClient.delete_collections(\"Unstructured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Delete custom classifications and entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete custom classifications\n",
    "for classification in classifications:\n",
    "    purviewClient.delete_type(classification)\n",
    "\n",
    "# Delete custom Entity Types\n",
    "for entityName in entityTypes:\n",
    "    # if entityName == 'FileSystem':\n",
    "    edef = EntityTypeDef(\n",
    "        name = entityName,\n",
    "        superTypes= ['DataSet']\n",
    "    )\n",
    "    results = purviewClient.delete_typedefs(\n",
    "        entityDefs=[edef],\n",
    "        force_update=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all Jupyter notebook variables\n",
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
