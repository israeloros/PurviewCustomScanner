# Custom Purview Scanner Solution for SharePoint Online and Filesystems


I created this repository to demonstrate the implementation of a custom scanner solution in Microsoft Purview for SharePoint Online (SPO) and Filesystem (FS) using the Graph and Atlas REST APIs. The solution is intended to provide an alternative for scanning and classifying data in SPO and FS data sources, currently not supported natively by Microsoft Purview. I leveraged the [sharepoint-indexing-azure-cognitive-search](https://github.com/liamca/sharepoint-indexing-azure-cognitive-search/blob/main/README.md) solution created by `Liam Cavanagh` as the basis for accessing SharePoint online sites.

The main notebook and libraries are responsible for abstracting the different API calls to Purview, SPO, and LLMs in a simple way. At a high level, the architecture behind this solution and workflow can be represented by the following diagram:

<img src="images/high-level-architecture.png" alt="High Level Architecture">

1. Setup file crawler, by defining credentials, endpoints, file source locations, classifications, number of files to be sampled, etc.
2. File crawler will list all files located in data sources, randomly select the number of files specified in the sample, extract file contents, and convert documents to text format to be further analyzed.
3. Document text will be sent to Azure Open AI LLM (GPT-4) to be analyzed and classified based on the list of classifications configured in step 1.
4. File crawler will receive all the classifications generated by the LLM and roll the classifications up to the parent folder or site.
5. New assets will be created, classified, and organized in the desired collections in Purview using the Atlas API.

> ðŸ“Œ <b>Note:</b> Although this solution relies on the use of Azure Open AI LLM for the classification activities, you can replace it with your own custom scanner.

# ðŸš€ Getting Started


## Requirements

- <b>Jupyter</b> or <b>Conda</b> notebook support.
- <b>SharePoint Online Site</b>: For the Microsoft Graph REST API to be able to access your content, you will need to provide access to this REST API which will included granting [admin consent](https://learn.microsoft.com/en-us/azure/active-directory/develop/console-app-quickstart?pivots=devlang-python).
- <b>Azure AI Foundry LLM Deployment</b>: The deployed LLM will be used to classify the contents of the files discovered by the scanner process. You can learn more about how to get [started here](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/deployments-overview).
- <b>Entra ID Service Principal</b>: This Entra ID identity will be used to authenticate the solution with Microsoft SharePoint, Azure AI, and Microsoft Purview services.

# Configuration Steps

## Setting Up VSCode for Jupyter Notebooks
Follow these steps to create a virtual environment and set up your VSCode for running Jupyter Notebooks:

1. **Install VS Code and Python**:
   - Download and install Visual Studio Code from here.
   - Download and install Python from here.

2. **Install the Python Extension for VS Code**:
   - Open VS Code.
   - Go to the Extensions view by clicking the Extensions icon in the Activity Bar on the side of the window or by pressing `Ctrl+Shift+X`.
   - Search for "Python" and install the extension provided by Microsoft.

3. **Create a Virtual Environment**:
   - Open a terminal in VS Code (`Ctrl+``).
   - Run the following command to create a virtual environment:
     ```sh
     python -m venv .venv
     ```

4. **Activate the Virtual Environment**:
   - On Windows:
     ```sh
     .venv\Scripts\activate
     ```
   - On macOS/Linux:
     ```sh
     source .venv/bin/activate
     ```

5. **Install Jupyter**:
   - With the virtual environment activated, run the following command to install Jupyter:
     ```sh
     pip install jupyter
     ```

6. **Install Other Necessary Packages (Optional)**:
   - You can install other packages you might need, such as NumPy, Pandas, and Matplotlib:
     ```sh
     pip install -r requirements.txt
     ```

7. **Configure VS Code to Use the Virtual Environment**:
   - Open VS Code.
   - Press `Ctrl+Shift+P` to open the Command Palette.
   - Type "Python: Select Interpreter" and select it.
   - Choose the interpreter from the `.venv` directory.

8. **Open the custome_purview_scanner.ipynb Jupyter Notebook**:
   - Start using Jupyter notebooks in VS Code.

## Register Application (Service Principal)
To register your application and add the app's registration information to your solution manually, follow these steps:

- Sign in to the [Azure portal](https://portal.azure.com/) as an <b>Admin</b>
- Search for and select Microsoft Entra ID.
- Under Manage, select App registrations > New registration.
- Enter a Name for your application, for example <code>sp-PurviewScanner</code>. Users of your app might see this name, and you can change it later.
- Select Register
- Under Manage, select Certificates & secrets.
- Under Client secrets, select New client secret, enter a name, and then select Add. Record the value which will be the "Client Secret" in a safe location for use in a later step. It is recommended to save this secret in a Key Vault. <b>NOTE</b>: Do not copy the "Secret ID" as this is not needed.
- Under Manage, select API Permissions > Add a permission. 
- Select Microsoft Graph.
- Select Application permissions.
- Under the User node, select User.Read.All as well as Site.Read.All, then select Add permissions.
- If you notice that "Grant Admin Consent" is required, enable this now. Make sure all permissions have been granted admin consent. If you require an Admin, please see this [document](https://learn.microsoft.com/en-us/entra/identity-platform/index-service?pivots=devlang-python) for additional help.
- Click "Overview" and copy the "Application (client) ID" as well as the "Directory (tenant) ID"

## Grant Purview Roles to Application
To grant roles to the application within Microsoft Purview, please follow these steps:

- Sign in to the [Purview studio](https://purview.microsoft.com/) as an <b>Admin</b>
- Select the <b>Data Map</b> solution
- Inside of the Data Map, select the Default Domain
- Once in the default domain, select the <b>Role assignments</b> tab
- In the role assignments tab, grant <b>Collection admins</b> and <b>Data curators</b> roles to the application.
> ðŸ“Œ <b>Note:</b> If you want the scanned assets to stay in the default domain's root collection, you don't need to grante the Collection admins role.

## Grant Azure AI Foundry Roles to Application
This solution authenticates with the Azure AI Foundry service using the API Key method. Please feel free to modify the code to leverage other authentication methods as per your security standards.

## Configure environment variables

This solution uses environment variables to store configuration settings. You can start by copying the .env.sample file as .env in your environment. The resulting file should look like this:

```env
# Microsoft Entra ID Configuration
APP_NAME='[Your Service Principal Name]'
AZURE_TENANT_ID='[Your Azure Tenant ID]'
AZURE_CLIENT_ID='[Your Azure Client ID]'
AZURE_CLIENT_SECRET='[Your Azure Client Secret]'

# SharePoint Site Configuration
SITE_DOMAIN='[Your SharePoint Site Domain]'
SITE_NAME='[Your SharePoint Site Name]'

# Purview information
PURVIEW_ACCOUNT_NAME='[Your Purview Account Name]'
PURVIEW_ENDPOINT_URL='https://[Your Purview Account Name].purview.azure.com'
PURVIEW_TOKEN_URL='https://purview.azure.net'

# Azure AI Multi Service Account
AZURE_OPENAI_API_KEY='[Your Azure Open AI API Key]'
AZURE_OPENAI_ENDPOINT='https://[Your Azure Open AI Service Name].openai.azure.com/openai/deployments/[Your LLM Deployment Name]'
AZURE_OPENAI_DEPLOYMENT_NAME='[Your LLM Deployment Name]'
AZURE_OPENAI_LLM_MODEL='[Your LLM Model Name]'
AZURE_OPENAI_API_VERSION='2024-02-01'
```

Then, replace the placeholders (e.g., [Your Azure Tenant ID]) with your actual values.

+ `AZURE_TENANT_ID`, `AZURE_SUBSCRIPTION_ID`, `AZURE_CLIENT_ID`, and `AZURE_CLIENT_SECRET` are used for authentication with Azure Active Directory.
- `SITE_DOMAIN` and `SITE_NAME` specify the SharePoint site from which data will be extracted.
+ `PURVIEW_ACCOUNT_NAME`, `PURVIEW_ENDPOINT_URL`, and `PURVIEW_TOKEN_URL` are used to configure access to Purview's REST API.
- `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_DEPLOYMENT_NAME`, `AZURE_OPENAI_LLM_MODEL`, and `AZURE_OPENAI_API_VERSION` are used to configure the Azure AI Foundry service.

> ðŸ“Œ **Note**
> Remember not to commit the .env file to your version control system. Add it to your .gitignore file to prevent it from being tracked.


For detailed information on using the SharePoint / Microsoft Graph REST API, refer to the official [documentation](https://learn.microsoft.com/en-us/sharepoint/dev/apis/sharepoint-rest-graph).
You can also find additional information on how to use the Microsoft Purview REST API in the official [documentation](https://learn.microsoft.com/en-us/rest/api/purview/datamapdataplane/operation-groups?view=rest-purview-datamapdataplane-2023-09-01).


## ðŸ’¡ Solution main components

The solution consists of the following modules:

| Module | Description |
| ------ | ----------- |
| custom_purview_scanner.ipynb | Main notebook to run the solution |
| sharepoint_utils.py | Library containing SharePoint related class |
| purview_utils.py | Library containing Purview related functions |
| custom_logging.py | Library containing custom logging functions |